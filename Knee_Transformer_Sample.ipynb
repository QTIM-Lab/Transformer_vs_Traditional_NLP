{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2xMSv97_COF"
   },
   "source": [
    "# Performance Analysis of BioBERT in Radiology Report Classification\n",
    "- Author: Eric Yang\n",
    "- Created: 04/19/21\n",
    "\n",
    "Script adapted from BERT tutorial: \n",
    "- https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=2bBdb3pt8LuQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTIXaAbR4SKE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf                                   \n",
    "import torch                                              \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import pandas as pd                                       \n",
    "import numpy as np                                        \n",
    "from transformers import BertTokenizer                    \n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from keras.preprocessing.sequence import pad_sequences    \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix   \n",
    "from sklearn.utils import resample, shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRkwGGpjzrJg",
    "outputId": "b3615c53-44d0-4b58-cbd6-385bc75c605e"
   },
   "outputs": [],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HyoUeA96V0A"
   },
   "outputs": [],
   "source": [
    "# load data to df\n",
    "training_data = pd.read_csv('training_table.csv').loc[:,'ACC':'report_excerpts']\n",
    "testing_data = pd.read_csv('testing_table.csv').loc[:,'ACC':'report_excerpts']\n",
    "# remove rows where MRN = nan\n",
    "training_data = training_data.dropna(subset = ['MRN'])\n",
    "testing_data = testing_data.dropna(subset = ['MRN'])\n",
    "# get corpus, labels\n",
    "training_corpus = list(training_data['report_excerpts'])\n",
    "testing_corpus = list(testing_data['report_excerpts'])\n",
    "training_MM_labels = np.array(list(training_data['medial_meniscus_R']))\n",
    "training_LM_labels = np.array(list(training_data['lateral_meniscus_R']))\n",
    "testing_MM_labels = np.array(list(testing_data['medial_meniscus_R']))\n",
    "testing_LM_labels = np.array(list(testing_data['lateral_meniscus_R']))\n",
    "\n",
    "# CHANGE n_samp to perform sampling experiments\n",
    "n_samp = round(len(training_corpus)*0.1)\n",
    "training_corpus, training_LM_labels, training_MM_labels = shuffle(training_corpus, \n",
    "                                                                  training_LM_labels, \n",
    "                                                                  training_MM_labels,\n",
    "                                                                  n_samples = n_samp, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize, pad, and convert texts into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fTUw9tj7Hi8"
   },
   "outputs": [],
   "source": [
    "# load BioBERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNMSqR3r9kjj",
    "outputId": "1e2993ec-5eb4-4bd8-934f-20ad0d1e241e"
   },
   "outputs": [],
   "source": [
    "# Tokenize all of the training reports and map the tokens to their word IDs.\n",
    "input_ids_train = []\n",
    "\n",
    "for report in training_corpus:\n",
    "    encoded_report = tokenizer.encode(\n",
    "                        report,                      \n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    input_ids_train.append(encoded_report)\n",
    "\n",
    "# Print report 0, now as a list of IDs.\n",
    "print('Original: ', training_corpus[0])\n",
    "print('Token IDs:', input_ids_train[0])\n",
    "\n",
    "# Tokenize all of the testing reports and map the tokens to their word IDs.\n",
    "input_ids_test = []\n",
    "\n",
    "for report in testing_corpus:\n",
    "    encoded_report = tokenizer.encode(\n",
    "                        report,                      \n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    input_ids_test.append(encoded_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HS1IXnlHBK72",
    "outputId": "d09fd95f-a27e-42d0-ea64-bd3ba78d7524"
   },
   "outputs": [],
   "source": [
    "# get training report length summary\n",
    "MAX_LEN = max([len(rep) for rep in input_ids_train])\n",
    "print('Max report length: ', MAX_LEN)\n",
    "print('Min report length: ', min([len(rep) for rep in input_ids_train]))\n",
    "print('Mean report length: ', np.mean([len(rep) for rep in input_ids_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CP82wsSB1iD"
   },
   "outputs": [],
   "source": [
    "# pad all sentences to max report length\n",
    "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LF9gHFmYDDmG"
   },
   "outputs": [],
   "source": [
    "# Create attention masks, tells us which tokens are words and which are padding\n",
    "\n",
    "# train data\n",
    "attention_masks_train = []\n",
    "for rep in input_ids_train:\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in rep]\n",
    "    attention_masks_train.append(att_mask)\n",
    "\n",
    "# test data\n",
    "attention_masks_test = []\n",
    "for rep in input_ids_test:\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in rep]\n",
    "    attention_masks_test.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bhjOrKGD-bm"
   },
   "outputs": [],
   "source": [
    "# convert to pytorch tensors\n",
    "train_inputs = torch.tensor(input_ids_train)\n",
    "test_inputs = torch.tensor(input_ids_test)\n",
    "\n",
    "train_MM_labels = torch.tensor(training_MM_labels)\n",
    "train_LM_labels = torch.tensor(training_LM_labels)\n",
    "test_MM_labels = torch.tensor(testing_MM_labels)\n",
    "test_LM_labels = torch.tensor(testing_LM_labels)\n",
    "\n",
    "train_masks = torch.tensor(attention_masks_train)\n",
    "test_masks = torch.tensor(attention_masks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BteWAr9qFnue"
   },
   "outputs": [],
   "source": [
    "# define batch size for training using DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_LM_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_LM_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6693Qm2tG5Vw",
    "outputId": "ab58c565-bd63-4501-fcaa-5fad3dc17a90"
   },
   "outputs": [],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"dmis-lab/biobert-base-cased-v1.1\", \n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.  \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmkhezS6H49Y"
   },
   "outputs": [],
   "source": [
    "# define optimizer \n",
    "# try AdamW from huggingface\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "# learning rate scheduler\n",
    "epochs = 4\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dFQ7glswUtX",
    "outputId": "3c1fc2c5-8b67-4db2-d5eb-7801b904346e"
   },
   "outputs": [],
   "source": [
    "# perform training\n",
    "\n",
    "seed_val = 5\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    # Put the model into training mode. \n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # clear any previously calculated gradients before performing a backward pass.\n",
    "        model.zero_grad() \n",
    "\n",
    "        # Perform a forward pass\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # get loss\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader) \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBJ4qyg2vitR"
   },
   "outputs": [],
   "source": [
    "# func to calculate specificity, the rest of the metrics imported from sklearn\n",
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    spec = tn / (tn+fp)\n",
    "    return spec\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54gdYM-O2lT7",
    "outputId": "4adfe40d-cbc2-4d1a-b506-8c46ed1db5c8"
   },
   "outputs": [],
   "source": [
    "# perform testing\n",
    "accuracy_scores = []\n",
    "cohen_kappa_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "specificity_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(100):\n",
    "    testing_corpus_samp, testing_LM_labels_samp = resample(testing_corpus, testing_LM_labels, replace=True)\n",
    "\n",
    "    # Tokenize all of the testing reports and map the tokens to their word IDs.\n",
    "    input_ids_test = []\n",
    "\n",
    "    for report in testing_corpus_samp:\n",
    "        encoded_report = tokenizer.encode(\n",
    "                            report,                      \n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      )\n",
    "        input_ids_test.append(encoded_report)\n",
    "\n",
    "    # pad all sentences to max report length\n",
    "    input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                              value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # Create attention masks, tells us which tokens are words and which are padding\n",
    "    # test data\n",
    "    attention_masks_test = []\n",
    "    for rep in input_ids_test:\n",
    "        #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "        #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "        att_mask = [int(token_id > 0) for token_id in rep]\n",
    "        attention_masks_test.append(att_mask)\n",
    "\n",
    "    # convert to pytorch tensors\n",
    "    test_inputs = torch.tensor(input_ids_test)\n",
    "    test_masks = torch.tensor(attention_masks_test)\n",
    "    test_LM_labels_samp = torch.tensor(testing_LM_labels_samp)\n",
    "    # test_LM_labels = torch.tensor(testing_LM_labels_samp)\n",
    "\n",
    "    # Create the DataLoader for our validation set.\n",
    "    test_data = TensorDataset(test_inputs, test_masks, test_LM_labels_samp)\n",
    "    test_sampler = SequentialSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "    #print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n",
    "\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    predictions , true_labels = [], []\n",
    "\n",
    "    # Predict \n",
    "    for batch in test_dataloader:\n",
    "      # Add batch to GPU\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      \n",
    "      # Unpack the inputs from our dataloader\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "      \n",
    "      # Telling the model not to compute or store gradients, saving memory and \n",
    "      # speeding up prediction\n",
    "      with torch.no_grad():\n",
    "          # Forward pass, calculate logit predictions\n",
    "          outputs = model(b_input_ids, token_type_ids=None, \n",
    "                          attention_mask=b_input_mask)\n",
    "\n",
    "      logits = outputs[0]\n",
    "\n",
    "      # Move logits and labels to CPU\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "      \n",
    "      # Store predictions and true labels\n",
    "      predictions.append(logits)\n",
    "      true_labels.append(label_ids)\n",
    "\n",
    "    # Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "    # Combine the correct labels for each batch into a single list.\n",
    "    flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "    accuracy_scores.append(accuracy_score(flat_true_labels, flat_predictions))\n",
    "    precision_scores.append(precision_score(flat_true_labels, flat_predictions))\n",
    "    recall_scores.append(recall_score(flat_true_labels, flat_predictions))\n",
    "    specificity_scores.append(specificity(flat_true_labels, flat_predictions)) \n",
    "    f1_scores.append(f1_score(flat_true_labels, flat_predictions)) \n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHl0mpm7A49c",
    "outputId": "2568037b-64ab-40af-b1c5-d3bb89e7a438"
   },
   "outputs": [],
   "source": [
    "# format bootstrapping results\n",
    "accuracy_scores = sorted(accuracy_scores, reverse = False)\n",
    "precision_scores = sorted(precision_scores, reverse = False)\n",
    "recall_scores = sorted(recall_scores, reverse = False)\n",
    "specificity_scores = sorted(specificity_scores, reverse = False)\n",
    "f1_scores = sorted(f1_scores, reverse = False)\n",
    "accuracy_CI = ((accuracy_scores[1]+accuracy_scores[2])/2, accuracy_scores[49], (accuracy_scores[97]+accuracy_scores[98])/2)\n",
    "precision_CI = ((precision_scores[1]+precision_scores[2])/2, precision_scores[49], (precision_scores[97]+precision_scores[98])/2)\n",
    "recall_CI = ((recall_scores[1]+recall_scores[2])/2, recall_scores[49], (recall_scores[97]+recall_scores[98])/2)\n",
    "specificity_CI = ((specificity_scores[1]+specificity_scores[2])/2, specificity_scores[49], (specificity_scores[97]+specificity_scores[98])/2)\n",
    "f1_CI = ((f1_scores[1]+f1_scores[2])/2, f1_scores[49], (f1_scores[97]+f1_scores[98])/2)\n",
    "results = {'accuracy_CI':accuracy_CI,\n",
    "           'precision_CI':precision_CI,\n",
    "           'recall_CI':recall_CI,\n",
    "           'specificity_CI':specificity_CI,\n",
    "           'f1_CI':f1_CI}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BioBERT_knee_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
