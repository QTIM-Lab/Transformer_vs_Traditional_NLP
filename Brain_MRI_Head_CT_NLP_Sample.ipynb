{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27deb1b2",
   "metadata": {},
   "source": [
    "# Performance Analysis of Natural Language Processing Techniques in Radiology Report Classification - Brain MRI and Head CT dataset\n",
    "\n",
    "- Author: Eric Yang\n",
    "- Created September 21st, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25787f42",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b289f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import loguniform\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.utils import resample, shuffle\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.util import mark_negation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1fc377",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in brain MRI and head CT data\n",
    "mri_data = pd.read_csv('../Data/Brain_MRI_head_CT/sample1000_brainMRIs_2017to2020_Min_FINAL.csv').dropna(subset = ['IMPRESSION'])\n",
    "ct_data = pd.read_csv('../Data/Brain_MRI_head_CT/sample1000_headCTs_2017to2020_FD_FINAL.csv').dropna(subset = ['IMPRESSION'])\n",
    "head_data = pd.concat([mri_data, ct_data])\n",
    "\n",
    "# remove name column\n",
    "head_data.drop('NAME', axis = 1, inplace = True)\n",
    "\n",
    "# for each 'REPORT', filter for sentences that contain desired expression\n",
    "def excerpt_fun(data, column, expression_list):\n",
    "    # data is df\n",
    "    # column is either 'REPORT' or 'IMPRESSION'\n",
    "    # expression_list is a list of regex expressions of interest\n",
    "    excerpts = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        text = data.iloc[i][column]\n",
    "        matches = []\n",
    "        for exp in expression_list:\n",
    "            matches += re.findall(exp, text, flags=re.IGNORECASE) \n",
    "        excerpt = ' '.join([a[0] for a in matches])\n",
    "        excerpts.append(excerpt)\n",
    "    return(excerpts)\n",
    "\n",
    "# filter for sentences of interest\n",
    "head_data['impression_excerpts'] = excerpt_fun(head_data,'IMPRESSION', [r\"([^.]*?(infarct|ischem)[^.]*\\.)\"])\n",
    "\n",
    "# train test split on MRN column\n",
    "all_MRNs = list(set(head_data['MRN']))\n",
    "np.random.seed(314)\n",
    "np.random.shuffle(all_MRNs)\n",
    "training_MRNs = all_MRNs[0:int(len(all_MRNs)*0.8)]\n",
    "testing_MRNs = all_MRNs[int(len(all_MRNs)*0.8):]\n",
    "training_data = head_data[head_data['MRN'].isin(training_MRNs)]\n",
    "testing_data = head_data[head_data['MRN'].isin(testing_MRNs)]\n",
    "\n",
    "# get training and testing corpus, labels\n",
    "all_corpus = list(head_data['impression_excerpts'])\n",
    "training_corpus = list(training_data['impression_excerpts'])\n",
    "training_infarct_labels = np.array(list(training_data['ACUTE_INFARCT']))\n",
    "\n",
    "testing_corpus = list(testing_data['impression_excerpts'])\n",
    "testing_infarct_labels = np.array(list(testing_data['ACUTE_INFARCT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51438ccb",
   "metadata": {},
   "source": [
    "## Define evaluation metrics and bootstrapping workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbfae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation functions\n",
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    spec = tn / (tn+fp)\n",
    "    return spec\n",
    "\n",
    "# Testing with bootstrap 95%\n",
    "def test_bootstrap(X_test, test_labels, clf):\n",
    "    '''\n",
    "    Testing of algorithm with generation of bootstrap 95% CI\n",
    "    Output:\n",
    "    tuples with performance metrics and boostrap 95% CI (5%, 50%, 95%tiles)\n",
    "    '''\n",
    "    accuracy_scores = []\n",
    "    cohen_kappa_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    specificity_scores = []\n",
    "    f1_scores = []\n",
    "    for i in tqdm(range(1000)):\n",
    "        testing_sample, testing_labels = resample(X_test, test_labels, replace=True)\n",
    "        predicted = clf.predict(testing_sample)\n",
    "        accuracy_scores.append(accuracy_score(testing_labels, predicted))\n",
    "        precision_scores.append(precision_score(testing_labels, predicted))\n",
    "        recall_scores.append(recall_score(testing_labels, predicted))\n",
    "        specificity_scores.append(specificity(testing_labels, predicted))\n",
    "        f1_scores.append(f1_score(testing_labels, predicted))\n",
    "    accuracy_scores = sorted(accuracy_scores, reverse = False)\n",
    "    precision_scores = sorted(precision_scores, reverse = False)\n",
    "    recall_scores = sorted(recall_scores, reverse = False)\n",
    "    specificity_scores = sorted(specificity_scores, reverse = False)\n",
    "    f1_scores = sorted(f1_scores, reverse = False)\n",
    "    accuracy_CI = (accuracy_scores[24], accuracy_scores[499], accuracy_scores[974])\n",
    "    precision_CI = (precision_scores[24], precision_scores[499], precision_scores[974])\n",
    "    recall_CI = (recall_scores[24], recall_scores[499], recall_scores[974])\n",
    "    specificity_CI = (specificity_scores[24], specificity_scores[499], specificity_scores[974])\n",
    "    f1_CI = (f1_scores[24], f1_scores[499], f1_scores[974])\n",
    "    results = {'accuracy_CI':accuracy_CI,\n",
    "               'precision_CI':precision_CI,\n",
    "               'recall_CI':recall_CI,\n",
    "               'specificity_CI':specificity_CI,\n",
    "               'f1_CI':f1_CI\n",
    "               }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831e615",
   "metadata": {},
   "source": [
    "## Bag of words with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1824812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words with NLTK\n",
    "vectorizer = CountVectorizer(analyzer = 'word', \n",
    "                             tokenizer = lambda text: mark_negation(word_tokenize(text)),  \n",
    "                             ngram_range = (1,3), \n",
    "                             min_df = 0.05\n",
    "                             )\n",
    "X_train_bow = vectorizer.fit_transform(training_corpus).toarray()\n",
    "vectorizer_features = vectorizer.get_feature_names()\n",
    "X_test_bow = vectorizer.transform(testing_corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7babfc",
   "metadata": {},
   "source": [
    "## XGBoost with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost training using BOW for acute/subacute ischemic infarct prediction\n",
    "param_dist = {'colsample_bytree':uniform(0.01,1),\n",
    "              'eta':uniform(0,1),\n",
    "              \"max_depth\": sp_randint(3,11),\n",
    "              \"min_child_weight\": sp_randint(1, 11)}\n",
    "XGBmodel_bow_infarct = XGBClassifier()\n",
    "random_search = RandomizedSearchCV(XGBmodel_bow_infarct, param_distributions=param_dist, scoring='f1',random_state=314)\n",
    "search = random_search.fit(X_train_bow, training_infarct_labels)\n",
    "XGBmodel_bow_infarct = search.best_estimator_\n",
    "\n",
    "# evaluate performance on acute/subacute ischemic infarct, BOW XGBoost model\n",
    "results_infarct_xgb_bow = test_bootstrap(X_test_bow, testing_infarct_labels, XGBmodel_bow_infarct)\n",
    "print(results_infarct_xgb_bow)\n",
    "\n",
    "# look at important features of BOW XGBoost model on acute/subacute ischemic infarct prediction\n",
    "# importance = how many times each feature is split on\n",
    "XGBmodel_bow_infarct.get_booster().feature_names = vectorizer_features\n",
    "plot_importance(XGBmodel_bow_infarct, max_num_features=10, title = 'Feature importance of BOW XGBoost model trained for acute/subacute ischemic infarct prediction')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075189f5",
   "metadata": {},
   "source": [
    "## Random forest with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest training using BOW for acute/subacute ischemic infarct prediction\n",
    "param_dist = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 5)],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              \"max_depth\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              'min_samples_split': [2, 5, 10]}\n",
    "RFmodel_bow_infarct = RandomForestClassifier()\n",
    "random_search = RandomizedSearchCV(RFmodel_bow_infarct, param_distributions=param_dist, scoring='f1',random_state=314)\n",
    "search = random_search.fit(X_train_bow, training_infarct_labels)\n",
    "RFmodel_bow_infarct = search.best_estimator_\n",
    "\n",
    "# evaluate performance on acute/subacute ischemic infarct, BOW RF model\n",
    "results_infarct_rf_bow = test_bootstrap(X_test_bow, testing_infarct_labels, RFmodel_bow_infarct)\n",
    "print(results_infarct_rf_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c890a1",
   "metadata": {},
   "source": [
    "## Logistic regression with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression training using BOW for acute/subacute ischemic infarct prediction\n",
    "param_dist = {'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "              'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "              'C': loguniform(1e-5, 100)}\n",
    "LOGmodel_bow_infarct = LogisticRegression()\n",
    "random_search = RandomizedSearchCV(LOGmodel_bow_infarct, param_distributions=param_dist, scoring='f1',random_state=315)\n",
    "search = random_search.fit(X_train_bow, training_infarct_labels)\n",
    "LOGmodel_bow_infarct = search.best_estimator_\n",
    "\n",
    "# evaluate performance on acute/subacute ischemic infarct, BOW logistic regression model\n",
    "results_infarct_log_bow = test_bootstrap(X_test_bow, testing_infarct_labels, LOGmodel_bow_infarct)\n",
    "print(results_infarct_log_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4ea8e",
   "metadata": {},
   "source": [
    "## Load external validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fec40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in brain MRI and head CT data\n",
    "ext_head_data = pd.read_csv('../Data/Brain_MRI_Head_CT/CT_MR_data_concatenated.csv', index_col = 0).dropna(subset = ['IMPRESSION'])\n",
    "\n",
    "# remove name column\n",
    "ext_head_data.drop('Name', axis = 1, inplace = True)\n",
    "\n",
    "# filter for sentences of interest\n",
    "ext_head_data['impression_excerpts'] = excerpt_fun(ext_head_data,'IMPRESSION', [r\"([^.]*?(infarct|ischem)[^.]*\\.)\"])\n",
    "\n",
    "# get training and testing corpus, labels\n",
    "ext_all_corpus = list(ext_head_data['impression_excerpts'])\n",
    "ext_infarct_labels = np.array(list(ext_head_data['ACUTE_INFARCT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore data\n",
    "print(\"Total number of patients:\", len(set(ext_head_data['Mrn'])))\n",
    "print(\"Total number of brain MRIs and head CTs:\", len(ext_head_data))\n",
    "print(\"Total number of acute/subacute ischemic infarct cases:\", len(ext_head_data[ext_head_data['ACUTE_INFARCT'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873508b4",
   "metadata": {},
   "source": [
    "## Perform subsampling experiments\n",
    "- This is essentially the first half of the notebook on loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3579a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each NLP model for each proportion\n",
    "\n",
    "for i, (prop, tag) in enumerate(zip(proportions, file_tags)):\n",
    "    # evaluate performance on acute/subacute ischemic infarct, BOW XGBoost model, ext dataset\n",
    "    results_infarct_xgb_bow = test_bootstrap(X_test_bow, ext_infarct_labels, xgb_bow_models[i])\n",
    "    ext_xgb_bow_results.append(results_infarct_xgb_bow)\n",
    "    \n",
    "    # evaluate performance on acute/subacute ischemic infarct, BOW RF model, ext dataset\n",
    "    results_infarct_rf_bow = test_bootstrap(X_test_bow, ext_infarct_labels, rf_bow_models[i])\n",
    "    ext_rf_bow_results.append(results_infarct_rf_bow)\n",
    "    \n",
    "    # evaluate performance on acute/subacute ischemic infarct, BOW log reg model, ext dataset\n",
    "    results_infarct_log_bow = test_bootstrap(X_test_bow, ext_infarct_labels, log_bow_models[i])\n",
    "    ext_log_bow_results.append(results_infarct_log_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88e324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define proportions\n",
    "proportions = np.array([0.025, 0.10, 0.25, 0.50, 0.75, 1.00])\n",
    "file_tags = np.array(['025', '10', '25', '50', '75', ''])\n",
    "\n",
    "# loop through NLP workflow for each proportion\n",
    "xgb_bow_sampling_results = []\n",
    "rf_bow_sampling_results = []\n",
    "log_bow_sampling_results = []\n",
    "ext_xgb_bow_results = []\n",
    "ext_rf_bow_results = []\n",
    "ext_log_bow_results = []\n",
    "xgb_clin_ent_sampling_results = []\n",
    "xgb_clin_emb_sampling_results = []\n",
    "for prop, tag in zip(proportions, file_tags):\n",
    "    n_samp = round(len(training_corpus)*prop)\n",
    "    np.random.seed(314)\n",
    "    sample_indices = np.random.choice(range(len(training_corpus)), n_samp, replace = False)\n",
    "    sub_training_data = training_data.iloc[sample_indices,:]\n",
    "    sub_training_data.to_csv('../Data/Brain_MRI_Head_CT/training_data' + tag + '.csv')\n",
    "    sub_training_corpus = sub_training_data['impression_excerpts']\n",
    "    sub_training_labels = sub_training_data['ACUTE_INFARCT']\n",
    "    \n",
    "    # XGB BOW\n",
    "    param_dist = {'colsample_bytree':uniform(0.01,1),\n",
    "              'eta':uniform(0,1),\n",
    "              \"max_depth\": sp_randint(3,11),\n",
    "              \"min_child_weight\": sp_randint(1, 11)}\n",
    "    X_train_bow = vectorizer.fit_transform(sub_training_corpus).toarray()\n",
    "    vectorizer_features = vectorizer.get_feature_names()\n",
    "    X_test_bow = vectorizer.transform(testing_corpus).toarray()\n",
    "    XGBmodel_bow_infarct = XGBClassifier()\n",
    "    random_search = RandomizedSearchCV(XGBmodel_bow_infarct, param_distributions=param_dist, scoring='f1',random_state=314)\n",
    "    search = random_search.fit(X_train_bow, sub_training_labels)\n",
    "    XGBmodel_bow_infarct = search.best_estimator_\n",
    "    # evaluate performance on acute/subacute ischemic infarct, BOW XGBoost model\n",
    "    results_infarct_xgb_bow = test_bootstrap(X_test_bow, testing_infarct_labels, XGBmodel_bow_infarct)\n",
    "    xgb_bow_sampling_results.append(results_infarct_xgb_bow)\n",
    "    ext_X_test_bow = vectorizer.transform(ext_all_corpus).toarray()\n",
    "    ext_results_infarct_xgb_bow = test_bootstrap(ext_X_test_bow, ext_infarct_labels, XGBmodel_bow_infarct)\n",
    "    ext_xgb_bow_results.append(ext_results_infarct_xgb_bow)\n",
    "    \n",
    "    # Random Forest training using BOW for acute/subacute ischemic infarct prediction\n",
    "    param_dist = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 5)],\n",
    "                  'max_features': ['auto', 'sqrt'],\n",
    "                  \"max_depth\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "                  \"min_samples_leaf\": sp_randint(1, 11),\n",
    "                  'min_samples_split': [2, 5, 10]}\n",
    "    RFmodel_bow_infarct = RandomForestClassifier()\n",
    "    random_search = RandomizedSearchCV(RFmodel_bow_infarct, param_distributions=param_dist, scoring='f1',random_state=314)\n",
    "    search = random_search.fit(X_train_bow, sub_training_labels)\n",
    "    RFmodel_bow_infarct = search.best_estimator_\n",
    "    # evaluate performance on acute/subacute ischemic infarct, BOW RF model\n",
    "    results_infarct_rf_bow = test_bootstrap(X_test_bow, testing_infarct_labels, RFmodel_bow_infarct)\n",
    "    rf_bow_sampling_results.append(results_infarct_rf_bow)\n",
    "    ext_results_infarct_rf_bow = test_bootstrap(ext_X_test_bow, ext_infarct_labels, RFmodel_bow_infarct)\n",
    "    ext_rf_bow_results.append(ext_results_infarct_rf_bow)\n",
    "    \n",
    "    # Logistic regression training using BOW for acute/subacute ischemic infarct prediction\n",
    "    param_dist = {'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                  'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "                  'C': loguniform(1e-5, 100)}\n",
    "    LOGmodel_bow_infarct = LogisticRegression()\n",
    "    random_search = RandomizedSearchCV(LOGmodel_bow_infarct, param_distributions=param_dist, scoring='f1',random_state=315)\n",
    "    search = random_search.fit(X_train_bow, sub_training_labels)\n",
    "    LOGmodel_bow_infarct = search.best_estimator_\n",
    "    # evaluate performance on acute/subacute ischemic infarct, BOW logistic regression model\n",
    "    results_infarct_log_bow = test_bootstrap(X_test_bow, testing_infarct_labels, LOGmodel_bow_infarct)\n",
    "    log_bow_sampling_results.append(results_infarct_log_bow)\n",
    "    ext_results_infarct_log_bow = test_bootstrap(ext_X_test_bow, ext_infarct_labels, LOGmodel_bow_infarct)\n",
    "    ext_log_bow_results.append(ext_results_infarct_log_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33b28d",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ed230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot results\n",
    "condition = ['Acute/subacute Ischemic Infarct']\n",
    "all_results_infarct = [xgb_bow_sampling_results, rf_bow_sampling_results, log_bow_sampling_results] \n",
    "all_results = [all_results_infarct]\n",
    "method_names = ['XGBoost w/ bag of words', 'Random Forest w/ bag of words', 'Logistic Regression w/ bag of words']\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F1 Score']\n",
    "sample_size = np.around(len(training_corpus)*proportions)\n",
    "for cond, res in zip(condition, all_results): # for each condition, we only have 1 here\n",
    "    for metric_i, metric in enumerate(metrics): # for each metric\n",
    "        for method_results, method_name in zip(res, method_names): # for each NLP method\n",
    "            means = []\n",
    "            lower = []\n",
    "            upper = []\n",
    "            for prop in range(len(sample_size)):\n",
    "                lower.append(list(method_results[prop].values())[metric_i][0])\n",
    "                means.append(list(method_results[prop].values())[metric_i][1])\n",
    "                upper.append(list(method_results[prop].values())[metric_i][2])\n",
    "            plt.errorbar(sample_size, means, \n",
    "            yerr = [(np.array(means)-np.array(lower)).tolist(),(np.array(upper)-np.array(means)).tolist()], \n",
    "            fmt = '-o',\n",
    "            label = method_name)\n",
    "        plt.ylim([0,1])\n",
    "        plt.xlabel('Number of Training Samples',size=13)\n",
    "        plt.ylabel(metric,size=13)\n",
    "        plt.title(cond + ' Classification',size=13)\n",
    "        plt.legend(loc=\"lower center\",ncol=2, bbox_to_anchor=(0.5, -0.4))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14371e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot results\n",
    "condition = ['Acute/subacute Ischemic Infarct']\n",
    "ext_results = [ext_xgb_bow_results, ext_rf_bow_results, ext_log_bow_results]\n",
    "all_results = [ext_results]\n",
    "method_names = ['XGBoost w/ bag of words', 'Random Forest w/ bag of words', 'Logistic Regression w/ bag of words']\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F1 Score']\n",
    "sample_size = np.around(len(training_corpus)*proportions)\n",
    "for cond, res in zip(condition, all_results): # for each condition, we only have 1 here\n",
    "    for metric_i, metric in enumerate(metrics): # for each metric\n",
    "        for method_results, method_name in zip(res, method_names): # for each NLP method\n",
    "            means = []\n",
    "            lower = []\n",
    "            upper = []\n",
    "            for prop in range(len(sample_size)):\n",
    "                lower.append(list(method_results[prop].values())[metric_i][0])\n",
    "                means.append(list(method_results[prop].values())[metric_i][1])\n",
    "                upper.append(list(method_results[prop].values())[metric_i][2])\n",
    "            plt.errorbar(sample_size, means, \n",
    "            yerr = [(np.array(means)-np.array(lower)).tolist(),(np.array(upper)-np.array(means)).tolist()], \n",
    "            fmt = '-o',\n",
    "            label = method_name)\n",
    "        plt.ylim([0,1])\n",
    "        plt.xlabel('Number of Training Samples',size=13)\n",
    "        plt.ylabel(metric,size=13)\n",
    "        plt.title(cond + ' Classification',size=13)\n",
    "        plt.legend(loc=\"lower center\",ncol=2, bbox_to_anchor=(0.5, -0.4))\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
